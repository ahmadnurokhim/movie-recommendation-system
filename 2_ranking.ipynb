{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ratings and movies data\n",
    "ratings = pd.read_csv(\"data/ratings_200k.csv\")\n",
    "movies = pd.read_csv('data/movies_2000.csv')\n",
    "\n",
    "# Get movie title to ratings DF\n",
    "ratings = pd.merge(ratings, movies[['movieId', 'title']], on='movieId')[['userId', 'title', 'rating']]\n",
    "\n",
    "# Convert value to byte\n",
    "ratings = ratings.apply(lambda x: x.apply(lambda y: str(y).encode()))\n",
    "\n",
    "# Convert DF to TF dataset\n",
    "ratings = tf.data.Dataset.from_tensor_slices(ratings)\n",
    "\n",
    "# Map so each row can be called by its name\n",
    "ratings = ratings.map(lambda x: {\n",
    "    'userId': x[0],\n",
    "    'title': x[1],\n",
    "    'rating': float(b'2.5')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data\n",
    "shuffled = ratings.shuffle(200000, reshuffle_each_iteration=False)\n",
    "\n",
    "# Split train test\n",
    "train = shuffled.take(160000)\n",
    "test = shuffled.skip(160000).take(40000)\n",
    "\n",
    "# Get unique movie title and user id lists to be used as vocabulary\n",
    "movie_titles = ratings.batch(1000000).map(lambda x: x['title'])\n",
    "user_ids = ratings.batch(1000000).map(lambda x: x['title'])\n",
    "\n",
    "uniq_movie_title = np.unique(np.concatenate(list(movie_titles)))\n",
    "uniq_user_id = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ranking model\n",
    "class RankingModel(tf.keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        embedding_dims = 32\n",
    "\n",
    "        # User embedding model        \n",
    "        self.movie_embedding = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=uniq_movie_title),\n",
    "            tf.keras.layers.Embedding(len(uniq_movie_title) + 1, embedding_dims)\n",
    "        ])\n",
    "\n",
    "        # Movie embedding model\n",
    "        self.user_embedding = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.StringLookup(vocabulary=uniq_user_id),\n",
    "            tf.keras.layers.Embedding(len(uniq_user_id) + 1, embedding_dims)\n",
    "        ])\n",
    "\n",
    "        # Rating prediction model\n",
    "        self.rating = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(256, 'relu'),\n",
    "            tf.keras.layers.Dense(64, 'relu'),\n",
    "            tf.keras.layers.Dense(1) # This will output the predicted rating\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_id, movie_title = inputs\n",
    "\n",
    "        user_embedding = self.user_embedding(user_id)\n",
    "        movie_embedding = self.movie_embedding(movie_title)\n",
    "\n",
    "        return self.rating(tf.concat([user_embedding, movie_embedding], axis=1)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define movie recommender model\n",
    "class MovieRecModel(tfrs.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel()\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, inputs: Dict[Text, tf.Tensor]):\n",
    "        return self.ranking_model((inputs['userId'], inputs['title']))\n",
    "        \n",
    "\n",
    "    def compute_loss(self, inputs: Dict[Text, tf.Tensor], training: bool = False) -> tf.Tensor:\n",
    "        rating_prediction = self.ranking_model((inputs['userId'], inputs['title']))\n",
    "\n",
    "        return self.task(labels=inputs['rating'], predictions=rating_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "16/16 [==============================] - 4s 59ms/step - root_mean_squared_error: 0.9462 - loss: 0.8455 - regularization_loss: 0.0000e+00 - total_loss: 0.8455\n",
      "Epoch 2/30\n",
      "16/16 [==============================] - 1s 33ms/step - root_mean_squared_error: 0.1397 - loss: 0.0187 - regularization_loss: 0.0000e+00 - total_loss: 0.0187\n",
      "Epoch 3/30\n",
      "16/16 [==============================] - 1s 36ms/step - root_mean_squared_error: 0.0445 - loss: 0.0019 - regularization_loss: 0.0000e+00 - total_loss: 0.0019\n",
      "Epoch 4/30\n",
      "16/16 [==============================] - 0s 31ms/step - root_mean_squared_error: 0.0196 - loss: 3.7934e-04 - regularization_loss: 0.0000e+00 - total_loss: 3.7934e-04\n",
      "Epoch 5/30\n",
      "16/16 [==============================] - 0s 30ms/step - root_mean_squared_error: 0.0166 - loss: 2.7347e-04 - regularization_loss: 0.0000e+00 - total_loss: 2.7347e-04\n",
      "Epoch 6/30\n",
      "16/16 [==============================] - 0s 30ms/step - root_mean_squared_error: 0.0160 - loss: 2.5507e-04 - regularization_loss: 0.0000e+00 - total_loss: 2.5507e-04\n",
      "Epoch 7/30\n",
      "16/16 [==============================] - 0s 30ms/step - root_mean_squared_error: 0.0155 - loss: 2.4084e-04 - regularization_loss: 0.0000e+00 - total_loss: 2.4084e-04\n",
      "Epoch 8/30\n",
      "16/16 [==============================] - 0s 30ms/step - root_mean_squared_error: 0.0151 - loss: 2.2721e-04 - regularization_loss: 0.0000e+00 - total_loss: 2.2721e-04\n",
      "Epoch 9/30\n",
      "16/16 [==============================] - 1s 31ms/step - root_mean_squared_error: 0.0147 - loss: 2.1439e-04 - regularization_loss: 0.0000e+00 - total_loss: 2.1439e-04\n",
      "Epoch 10/30\n",
      "16/16 [==============================] - 1s 35ms/step - root_mean_squared_error: 0.0142 - loss: 2.0243e-04 - regularization_loss: 0.0000e+00 - total_loss: 2.0243e-04\n",
      "Epoch 11/30\n",
      "16/16 [==============================] - 0s 29ms/step - root_mean_squared_error: 0.0138 - loss: 1.9131e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.9131e-04\n",
      "Epoch 12/30\n",
      "16/16 [==============================] - 0s 29ms/step - root_mean_squared_error: 0.0135 - loss: 1.8100e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.8100e-04\n",
      "Epoch 13/30\n",
      "16/16 [==============================] - 0s 29ms/step - root_mean_squared_error: 0.0131 - loss: 1.7139e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.7139e-04\n",
      "Epoch 14/30\n",
      "16/16 [==============================] - 0s 29ms/step - root_mean_squared_error: 0.0128 - loss: 1.6240e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.6240e-04\n",
      "Epoch 15/30\n",
      "16/16 [==============================] - 0s 30ms/step - root_mean_squared_error: 0.0124 - loss: 1.5401e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.5401e-04\n",
      "Epoch 16/30\n",
      "16/16 [==============================] - 1s 31ms/step - root_mean_squared_error: 0.0121 - loss: 1.4615e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.4615e-04\n",
      "Epoch 17/30\n",
      "16/16 [==============================] - 1s 35ms/step - root_mean_squared_error: 0.0118 - loss: 1.3877e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.3877e-04\n",
      "Epoch 18/30\n",
      "16/16 [==============================] - 1s 31ms/step - root_mean_squared_error: 0.0115 - loss: 1.3182e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.3182e-04\n",
      "Epoch 19/30\n",
      "16/16 [==============================] - 1s 32ms/step - root_mean_squared_error: 0.0112 - loss: 1.2530e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.2530e-04\n",
      "Epoch 20/30\n",
      "16/16 [==============================] - 1s 32ms/step - root_mean_squared_error: 0.0109 - loss: 1.1918e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.1918e-04\n",
      "Epoch 21/30\n",
      "16/16 [==============================] - 1s 32ms/step - root_mean_squared_error: 0.0107 - loss: 1.1341e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.1341e-04\n",
      "Epoch 22/30\n",
      "16/16 [==============================] - 1s 34ms/step - root_mean_squared_error: 0.0104 - loss: 1.0798e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.0798e-04\n",
      "Epoch 23/30\n",
      "16/16 [==============================] - 0s 30ms/step - root_mean_squared_error: 0.0102 - loss: 1.0287e-04 - regularization_loss: 0.0000e+00 - total_loss: 1.0287e-04\n",
      "Epoch 24/30\n",
      "16/16 [==============================] - 1s 35ms/step - root_mean_squared_error: 0.0099 - loss: 9.8032e-05 - regularization_loss: 0.0000e+00 - total_loss: 9.8032e-05\n",
      "Epoch 25/30\n",
      "16/16 [==============================] - 0s 30ms/step - root_mean_squared_error: 0.0097 - loss: 9.3452e-05 - regularization_loss: 0.0000e+00 - total_loss: 9.3452e-05\n",
      "Epoch 26/30\n",
      "16/16 [==============================] - 0s 29ms/step - root_mean_squared_error: 0.0094 - loss: 8.9116e-05 - regularization_loss: 0.0000e+00 - total_loss: 8.9116e-05\n",
      "Epoch 27/30\n",
      "16/16 [==============================] - 0s 29ms/step - root_mean_squared_error: 0.0092 - loss: 8.5011e-05 - regularization_loss: 0.0000e+00 - total_loss: 8.5011e-05\n",
      "Epoch 28/30\n",
      "16/16 [==============================] - 0s 28ms/step - root_mean_squared_error: 0.0090 - loss: 8.1125e-05 - regularization_loss: 0.0000e+00 - total_loss: 8.1125e-05\n",
      "Epoch 29/30\n",
      "16/16 [==============================] - 1s 39ms/step - root_mean_squared_error: 0.0088 - loss: 7.7447e-05 - regularization_loss: 0.0000e+00 - total_loss: 7.7447e-05\n",
      "Epoch 30/30\n",
      "16/16 [==============================] - 0s 31ms/step - root_mean_squared_error: 0.0086 - loss: 7.3965e-05 - regularization_loss: 0.0000e+00 - total_loss: 7.3965e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1de01fa8a00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "model = MovieRecModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "# Cache the dataset\n",
    "cached_train = train.batch(10000).cache()\n",
    "cached_test = test.batch(5000).cache()\n",
    "\n",
    "# Fit the model to train dataset\n",
    "model.fit(cached_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 2s 18ms/step - root_mean_squared_error: 0.0085 - loss: 7.1587e-05 - regularization_loss: 0.0000e+00 - total_loss: 7.1587e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 0.008466300554573536,\n",
       " 'loss': 7.085403194651008e-05,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 7.085403194651008e-05}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model\n",
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4946513]\n",
      "[2.5149736]\n",
      "[2.4869032]\n"
     ]
    }
   ],
   "source": [
    "# Inference testing those movies for user 20\n",
    "rating_result = {}\n",
    "movies_to_test = ['Toy Story (1995)', 'Jumanji (1995)', 'Star Wars: The Last Jedi (2017)']\n",
    "for title in movies_to_test:\n",
    "    rating_result[title] =\\\n",
    "        model({'userId': np.array(['50']),\n",
    "               'title': np.array([title])})\n",
    "\n",
    "for x in rating_result.values():\n",
    "    print(x.numpy()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
