{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from typing import Dict, Text\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = tfds.load('movielens/100k-ratings', split='train')\n",
    "movies = tfds.load('movielens/100k-movies', split='train')\n",
    "\n",
    "ratings = ratings.map(lambda x: {\n",
    "    'movie_title': x['movie_title'],\n",
    "    'user_id': x['user_id']\n",
    "})\n",
    "\n",
    "# movies = movies.map(lambda x: {\n",
    "#     'movie_title': x['movie_title']\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [1] and element 1 had shape [2]. [Op:IteratorGetNext]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m movie_titles \u001b[39m=\u001b[39m movies\u001b[39m.\u001b[39mbatch(\u001b[39m1000\u001b[39m)\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m'\u001b[39m\u001b[39mmovie_title\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      8\u001b[0m user_ids \u001b[39m=\u001b[39m ratings\u001b[39m.\u001b[39mbatch(\u001b[39m1000000\u001b[39m)\u001b[39m.\u001b[39mmap(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m uniq_movie_titles \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39mconcatenate(\u001b[39mlist\u001b[39;49m(movie_titles)))\n\u001b[0;32m     11\u001b[0m uniq_user_ids \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(np\u001b[39m.\u001b[39mconcatenate(\u001b[39mlist\u001b[39m(user_ids)))\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:797\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    796\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 797\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_internal()\n\u001b[0;32m    798\u001b[0m   \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    799\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:780\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[39m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    779\u001b[0m \u001b[39mwith\u001b[39;00m context\u001b[39m.\u001b[39mexecution_mode(context\u001b[39m.\u001b[39mSYNC):\n\u001b[1;32m--> 780\u001b[0m   ret \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49miterator_get_next(\n\u001b[0;32m    781\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource,\n\u001b[0;32m    782\u001b[0m       output_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_types,\n\u001b[0;32m    783\u001b[0m       output_shapes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_output_shapes)\n\u001b[0;32m    785\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    786\u001b[0m     \u001b[39m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_element_spec\u001b[39m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3043\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3041\u001b[0m   \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3042\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m-> 3043\u001b[0m   _ops\u001b[39m.\u001b[39;49mraise_from_not_ok_status(e, name)\n\u001b[0;32m   3044\u001b[0m \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_FallbackException:\n\u001b[0;32m   3045\u001b[0m   \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7262\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7260\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7261\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7262\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} Cannot batch tensors with different shapes in component 0. First element had shape [1] and element 1 had shape [2]. [Op:IteratorGetNext]"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80000)\n",
    "test = shuffled.skip(80000).take(20000)\n",
    "\n",
    "movie_titles = movies.batch(1000).map(lambda x: x['movie_title'])\n",
    "user_ids = ratings.batch(1000000).map(lambda x: x['user_id'])\n",
    "\n",
    "uniq_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "uniq_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'movie_title': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs={'movie_title': <tf.Tensor 'args_0:0' shape=(None,) dtype=string>}. Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'string_lookup_15' (type StringLookup).\n\nExpected string, but got Tensor(\"args_0:0\", shape=(None,), dtype=string) of type 'Tensor'.\n\nCall arguments received by layer 'string_lookup_15' (type StringLookup):\n  • inputs={'movie_title': 'tf.Tensor(shape=(None,), dtype=string)'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 13\u001b[0m\n\u001b[0;32m      2\u001b[0m user_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      3\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mStringLookup(vocabulary\u001b[39m=\u001b[39muniq_user_ids),\n\u001b[0;32m      4\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mEmbedding(\u001b[39mlen\u001b[39m(uniq_user_ids) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, embedding_dimension)\n\u001b[0;32m      5\u001b[0m ])\n\u001b[0;32m      7\u001b[0m movie_model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      8\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mStringLookup(vocabulary\u001b[39m=\u001b[39muniq_user_ids),\n\u001b[0;32m      9\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mEmbedding(\u001b[39mlen\u001b[39m(uniq_movie_titles) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, embedding_dimension)\n\u001b[0;32m     10\u001b[0m ])\n\u001b[0;32m     12\u001b[0m metrics \u001b[39m=\u001b[39m tfrs\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mFactorizedTopK(\n\u001b[1;32m---> 13\u001b[0m     candidates\u001b[39m=\u001b[39mmovies\u001b[39m.\u001b[39;49mbatch(\u001b[39m128\u001b[39;49m)\u001b[39m.\u001b[39;49mmap(movie_model),\n\u001b[0;32m     14\u001b[0m     k\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m task \u001b[39m=\u001b[39m tfrs\u001b[39m.\u001b[39mtasks\u001b[39m.\u001b[39mRetrieval(\n\u001b[0;32m     18\u001b[0m     metrics\u001b[39m=\u001b[39mmetrics\n\u001b[0;32m     19\u001b[0m )\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2236\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[0;32m   2237\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[0;32m   2238\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[0;32m   2239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[1;32m-> 2240\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[0;32m   2241\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   2242\u001b[0m     map_func,\n\u001b[0;32m   2243\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[0;32m   2244\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[0;32m   2245\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[1;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m     34\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m debug_mode\u001b[39m.\u001b[39mDEBUG_MODE:\n\u001b[0;32m     35\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     36\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[0;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[0;32m     41\u001b[0m       input_dataset,\n\u001b[0;32m     42\u001b[0m       map_func,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     46\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[0;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[1;32m--> 107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[0;32m    108\u001b[0m     map_func,\n\u001b[0;32m    109\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[0;32m    110\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[0;32m    111\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[0;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[0;32m    113\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[0;32m    114\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[0;32m    119\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    255\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m    262\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    224\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[0;32m    233\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    234\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    235\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[0;32m    201\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m--> 202\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[0;32m    203\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m    204\u001b[0m   concrete_function\u001b[39m.\u001b[39m_arg_keywords \u001b[39m=\u001b[39m []  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[0;32m    164\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m   args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[0;32m    394\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[1;32m--> 396\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[0;32m    397\u001b[0m     args, kwargs, func_graph)\n\u001b[0;32m    399\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_function_captures  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[1;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    297\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[0;32m    299\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[1;32m--> 300\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m    301\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m    302\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m    303\u001b[0m         args,\n\u001b[0;32m    304\u001b[0m         kwargs,\n\u001b[0;32m    305\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    306\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[0;32m    307\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m    308\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m    309\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m    310\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[0;32m    311\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m    313\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m    314\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m    315\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m    318\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1214\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1212\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1214\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[0;32m   1216\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m func_outputs \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:238\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    233\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m    235\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    236\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    237\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    239\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    240\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:169\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    168\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 169\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m    170\u001b[0m ret \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    690\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    374\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 377\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    379\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:458\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    455\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    457\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    459\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py:396\u001b[0m, in \u001b[0;36m_AssertCompatible\u001b[1;34m(values, dtype)\u001b[0m\n\u001b[0;32m    394\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected any non-tensor type, but got a tensor instead.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    395\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 396\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected \u001b[39m\u001b[39m{\u001b[39;00mdtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00mmismatch\u001b[39m}\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    397\u001b[0m                   \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(mismatch)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer 'string_lookup_15' (type StringLookup).\n\nExpected string, but got Tensor(\"args_0:0\", shape=(None,), dtype=string) of type 'Tensor'.\n\nCall arguments received by layer 'string_lookup_15' (type StringLookup):\n  • inputs={'movie_title': 'tf.Tensor(shape=(None,), dtype=string)'}"
     ]
    }
   ],
   "source": [
    "embedding_dimension = 32\n",
    "user_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(vocabulary=uniq_user_ids),\n",
    "    tf.keras.layers.Embedding(len(uniq_user_ids) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "movie_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.StringLookup(vocabulary=uniq_user_ids),\n",
    "    tf.keras.layers.Embedding(len(uniq_movie_titles) + 1, embedding_dimension)\n",
    "])\n",
    "\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "    candidates=movies.batch(128).map(movie_model),\n",
    "    k=100\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "    metrics=metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensModel(tfrs.Model):\n",
    "    def __init__(self, user_model, movie_model):\n",
    "        super().__init__()\n",
    "        self.movie_model: tf.keras.Model = movie_model\n",
    "        self.user_model: tf.keras.Model = user_model\n",
    "        self.task: tf.keras.layers.Layer = task\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        user_embeddings = self.user_model(features['user_id'])\n",
    "        positive_movie_embeddings = self.movie_model(features['movie_title'])\n",
    "        \n",
    "        return self.task(user_embeddings, positive_movie_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\ipykernel_12168\\2190547765.py\", line 12, in compute_loss\n        return self.task(user_embeddings, positive_movie_embeddings)\n    File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_file773ekqpy.py\", line 128, in tf__call\n        ag__.if_stmt(ag__.ld(compute_metrics), if_body_5, else_body_5, get_state_7, set_state_7, (), 0)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_file773ekqpy.py\", line 124, in if_body_5\n        ag__.for_stmt(ag__.ld(self)._factorized_metrics, None, loop_body_1, get_state_6, set_state_6, (), {'iterate_names': 'metric'})\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_file773ekqpy.py\", line 123, in loop_body_1\n        ag__.converted_call(ag__.ld(update_ops).append, (ag__.converted_call(ag__.ld(metric).update_state, (ag__.ld(query_embeddings), ag__.ld(candidate_embeddings)[:ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(query_embeddings),), None, fscope)[0]]), dict(true_candidate_ids=ag__.ld(candidate_ids)), fscope),), None, fscope)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filewjtmcce9.py\", line 25, in tf__update_state\n        (top_k_predictions, retrieved_ids) = ag__.converted_call(ag__.ld(self)._candidates, (ag__.ld(query_embeddings),), dict(k=ag__.converted_call(ag__.ld(max), (ag__.ld(self)._ks,), None, fscope)), fscope)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 145, in tf__call\n        ag__.if_stmt(ag__.not_(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(self)._candidates.element_spec, ag__.ld(tuple)), None, fscope)), if_body_4, else_body_4, get_state_4, set_state_4, ('candidates', 'index_dtype'), 2)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 136, in if_body_4\n        candidates = ag__.converted_call(ag__.ld(self)._candidates.map, (ag__.ld(enumerate_rows),), None, fscope)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 118, in enumerate_rows\n        end_counter = ag__.converted_call(ag__.ld(self)._counter.assign_add, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(batch),), None, fscope_3)[0],), None, fscope_3)\n\n    TypeError: Exception encountered when calling layer 'retrieval_1' (type Retrieval).\n    \n    in user code:\n    \n        File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow_recommenders\\tasks\\retrieval.py\", line 197, in call  *\n            update_ops.append(\n        File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow_recommenders\\metrics\\factorized_top_k.py\", line 136, in update_state  *\n            top_k_predictions, retrieved_ids = self._candidates(\n        File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 145, in tf__call\n            ag__.if_stmt(ag__.not_(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(self)._candidates.element_spec, ag__.ld(tuple)), None, fscope)), if_body_4, else_body_4, get_state_4, set_state_4, ('candidates', 'index_dtype'), 2)\n        File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 136, in if_body_4\n            candidates = ag__.converted_call(ag__.ld(self)._candidates.map, (ag__.ld(enumerate_rows),), None, fscope)\n        File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 118, in enumerate_rows\n            end_counter = ag__.converted_call(ag__.ld(self)._counter.assign_add, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(batch),), None, fscope_3)[0],), None, fscope_3)\n    \n        TypeError: Exception encountered when calling layer 'streaming_2' (type Streaming).\n        \n        in user code:\n        \n            File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py\", line 470, in enumerate_rows  *\n                end_counter = self._counter.assign_add(tf.shape(batch)[0])\n        \n            TypeError: Expected any non-tensor type, but got a tensor instead.\n        \n        \n        Call arguments received by layer 'streaming_2' (type Streaming):\n          • queries=tf.Tensor(shape=(None, 32), dtype=float32)\n          • k=100\n    \n    \n    Call arguments received by layer 'retrieval_1' (type Retrieval):\n      • query_embeddings=tf.Tensor(shape=(None, 32), dtype=float32)\n      • candidate_embeddings=tf.Tensor(shape=(None, 32), dtype=float32)\n      • sample_weight=None\n      • candidate_sampling_probability=None\n      • candidate_ids=None\n      • compute_metrics=True\n      • compute_batch_metrics=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m cached_train \u001b[39m=\u001b[39m train\u001b[39m.\u001b[39mbatch(\u001b[39m8192\u001b[39m)\u001b[39m.\u001b[39mcache()\n\u001b[0;32m      5\u001b[0m cached_test \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mbatch(\u001b[39m4096\u001b[39m)\u001b[39m.\u001b[39mcache()\n\u001b[1;32m----> 7\u001b[0m model\u001b[39m.\u001b[39;49mfit(cached_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filetzevo4u3.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32md:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py:68\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Custom train step using the `compute_loss` method.\"\"\"\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m---> 68\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(inputs, training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     70\u001b[0m   \u001b[39m# Handle regularization losses as well.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m   regularization_loss \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlosses)\n",
      "Cell \u001b[1;32mIn[37], line 12\u001b[0m, in \u001b[0;36mMovieLensModel.compute_loss\u001b[1;34m(self, features, training)\u001b[0m\n\u001b[0;32m      9\u001b[0m user_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_model(features[\u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m positive_movie_embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmovie_model(features[\u001b[39m'\u001b[39m\u001b[39mmovie_title\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 12\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtask(user_embeddings, positive_movie_embeddings)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file773ekqpy.py:128\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, query_embeddings, candidate_embeddings, sample_weight, candidate_sampling_probability, candidate_ids, compute_metrics, compute_batch_metrics)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39melse_body_5\u001b[39m():\n\u001b[0;32m    127\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(compute_metrics), if_body_5, else_body_5, get_state_7, set_state_7, (), \u001b[39m0\u001b[39m)\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_9\u001b[39m():\n\u001b[0;32m    131\u001b[0m     \u001b[39mreturn\u001b[39;00m ()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file773ekqpy.py:124\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_5\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m     metric \u001b[39m=\u001b[39m itr_1\n\u001b[0;32m    123\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(update_ops)\u001b[39m.\u001b[39mappend, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(metric)\u001b[39m.\u001b[39mupdate_state, (ag__\u001b[39m.\u001b[39mld(query_embeddings), ag__\u001b[39m.\u001b[39mld(candidate_embeddings)[:ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mshape, (ag__\u001b[39m.\u001b[39mld(query_embeddings),), \u001b[39mNone\u001b[39;00m, fscope)[\u001b[39m0\u001b[39m]]), \u001b[39mdict\u001b[39m(true_candidate_ids\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(candidate_ids)), fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m--> 124\u001b[0m ag__\u001b[39m.\u001b[39;49mfor_stmt(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_factorized_metrics, \u001b[39mNone\u001b[39;49;00m, loop_body_1, get_state_6, set_state_6, (), {\u001b[39m'\u001b[39;49m\u001b[39miterate_names\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mmetric\u001b[39;49m\u001b[39m'\u001b[39;49m})\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file773ekqpy.py:123\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_5.<locals>.loop_body_1\u001b[1;34m(itr_1)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloop_body_1\u001b[39m(itr_1):\n\u001b[0;32m    122\u001b[0m     metric \u001b[39m=\u001b[39m itr_1\n\u001b[1;32m--> 123\u001b[0m     ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(update_ops)\u001b[39m.\u001b[39mappend, (ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(metric)\u001b[39m.\u001b[39;49mupdate_state, (ag__\u001b[39m.\u001b[39;49mld(query_embeddings), ag__\u001b[39m.\u001b[39;49mld(candidate_embeddings)[:ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(tf)\u001b[39m.\u001b[39;49mshape, (ag__\u001b[39m.\u001b[39;49mld(query_embeddings),), \u001b[39mNone\u001b[39;49;00m, fscope)[\u001b[39m0\u001b[39;49m]]), \u001b[39mdict\u001b[39;49m(true_candidate_ids\u001b[39m=\u001b[39;49mag__\u001b[39m.\u001b[39;49mld(candidate_ids)), fscope),), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filewjtmcce9.py:25\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__update_state\u001b[1;34m(self, query_embeddings, true_candidate_embeddings, true_candidate_ids, sample_weight)\u001b[0m\n\u001b[0;32m     23\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mand_((\u001b[39mlambda\u001b[39;00m : (ag__\u001b[39m.\u001b[39mld(true_candidate_ids) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)), (\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mnot_(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_candidates\u001b[39m.\u001b[39mis_exact, (), \u001b[39mNone\u001b[39;00m, fscope)))), if_body, else_body, get_state, set_state, (), \u001b[39m0\u001b[39m)\n\u001b[0;32m     24\u001b[0m positive_scores \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mreduce_sum, ((ag__\u001b[39m.\u001b[39mld(query_embeddings) \u001b[39m*\u001b[39m ag__\u001b[39m.\u001b[39mld(true_candidate_embeddings)),), \u001b[39mdict\u001b[39m(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)\n\u001b[1;32m---> 25\u001b[0m (top_k_predictions, retrieved_ids) \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_candidates, (ag__\u001b[39m.\u001b[39mld(query_embeddings),), \u001b[39mdict\u001b[39m(k\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mmax\u001b[39m), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_ks,), \u001b[39mNone\u001b[39;00m, fscope)), fscope)\n\u001b[0;32m     26\u001b[0m update_ops \u001b[39m=\u001b[39m []\n\u001b[0;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_4\u001b[39m():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py:145\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, queries, k)\u001b[0m\n\u001b[0;32m    143\u001b[0m index_dtype \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mindex_dtype\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    144\u001b[0m candidates \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mcandidates\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 145\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mnot_(ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39misinstance\u001b[39m), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_candidates\u001b[39m.\u001b[39melement_spec, ag__\u001b[39m.\u001b[39mld(\u001b[39mtuple\u001b[39m)), \u001b[39mNone\u001b[39;00m, fscope)), if_body_4, else_body_4, get_state_4, set_state_4, (\u001b[39m'\u001b[39m\u001b[39mcandidates\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mindex_dtype\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m2\u001b[39m)\n\u001b[0;32m    146\u001b[0m initial_state \u001b[39m=\u001b[39m (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mzeros, ((ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mshape, (ag__\u001b[39m.\u001b[39mld(queries),), \u001b[39mNone\u001b[39;00m, fscope)[\u001b[39m0\u001b[39m], \u001b[39m0\u001b[39m),), \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mfloat32), fscope), ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mzeros, ((ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mshape, (ag__\u001b[39m.\u001b[39mld(queries),), \u001b[39mNone\u001b[39;00m, fscope)[\u001b[39m0\u001b[39m], \u001b[39m0\u001b[39m),), \u001b[39mdict\u001b[39m(dtype\u001b[39m=\u001b[39mag__\u001b[39m.\u001b[39mld(index_dtype)), fscope))\n\u001b[0;32m    147\u001b[0m \u001b[39mwith\u001b[39;00m ag__\u001b[39m.\u001b[39mld(_wrap_batch_too_small_error)(ag__\u001b[39m.\u001b[39mld(k)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py:136\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.if_body_4\u001b[1;34m()\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mif_body_4\u001b[39m():\n\u001b[0;32m    135\u001b[0m     \u001b[39mnonlocal\u001b[39;00m index_dtype, candidates\n\u001b[1;32m--> 136\u001b[0m     candidates \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_candidates\u001b[39m.\u001b[39;49mmap, (ag__\u001b[39m.\u001b[39;49mld(enumerate_rows),), \u001b[39mNone\u001b[39;49;00m, fscope)\n\u001b[0;32m    137\u001b[0m     index_dtype \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mint32\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py:118\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.enumerate_rows\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    116\u001b[0m retval__3 \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m    117\u001b[0m starting_counter \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_counter\u001b[39m.\u001b[39mread_value, (), \u001b[39mNone\u001b[39;00m, fscope_3)\n\u001b[1;32m--> 118\u001b[0m end_counter \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_counter\u001b[39m.\u001b[39massign_add, (ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(tf)\u001b[39m.\u001b[39mshape, (ag__\u001b[39m.\u001b[39mld(batch),), \u001b[39mNone\u001b[39;00m, fscope_3)[\u001b[39m0\u001b[39m],), \u001b[39mNone\u001b[39;00m, fscope_3)\n\u001b[0;32m    119\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     do_return_3 \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow_recommenders\\models\\base.py\", line 68, in train_step\n        loss = self.compute_loss(inputs, training=True)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\ipykernel_12168\\2190547765.py\", line 12, in compute_loss\n        return self.task(user_embeddings, positive_movie_embeddings)\n    File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_file773ekqpy.py\", line 128, in tf__call\n        ag__.if_stmt(ag__.ld(compute_metrics), if_body_5, else_body_5, get_state_7, set_state_7, (), 0)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_file773ekqpy.py\", line 124, in if_body_5\n        ag__.for_stmt(ag__.ld(self)._factorized_metrics, None, loop_body_1, get_state_6, set_state_6, (), {'iterate_names': 'metric'})\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_file773ekqpy.py\", line 123, in loop_body_1\n        ag__.converted_call(ag__.ld(update_ops).append, (ag__.converted_call(ag__.ld(metric).update_state, (ag__.ld(query_embeddings), ag__.ld(candidate_embeddings)[:ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(query_embeddings),), None, fscope)[0]]), dict(true_candidate_ids=ag__.ld(candidate_ids)), fscope),), None, fscope)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filewjtmcce9.py\", line 25, in tf__update_state\n        (top_k_predictions, retrieved_ids) = ag__.converted_call(ag__.ld(self)._candidates, (ag__.ld(query_embeddings),), dict(k=ag__.converted_call(ag__.ld(max), (ag__.ld(self)._ks,), None, fscope)), fscope)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 145, in tf__call\n        ag__.if_stmt(ag__.not_(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(self)._candidates.element_spec, ag__.ld(tuple)), None, fscope)), if_body_4, else_body_4, get_state_4, set_state_4, ('candidates', 'index_dtype'), 2)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 136, in if_body_4\n        candidates = ag__.converted_call(ag__.ld(self)._candidates.map, (ag__.ld(enumerate_rows),), None, fscope)\n    File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 118, in enumerate_rows\n        end_counter = ag__.converted_call(ag__.ld(self)._counter.assign_add, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(batch),), None, fscope_3)[0],), None, fscope_3)\n\n    TypeError: Exception encountered when calling layer 'retrieval_1' (type Retrieval).\n    \n    in user code:\n    \n        File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow_recommenders\\tasks\\retrieval.py\", line 197, in call  *\n            update_ops.append(\n        File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow_recommenders\\metrics\\factorized_top_k.py\", line 136, in update_state  *\n            top_k_predictions, retrieved_ids = self._candidates(\n        File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 145, in tf__call\n            ag__.if_stmt(ag__.not_(ag__.converted_call(ag__.ld(isinstance), (ag__.ld(self)._candidates.element_spec, ag__.ld(tuple)), None, fscope)), if_body_4, else_body_4, get_state_4, set_state_4, ('candidates', 'index_dtype'), 2)\n        File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 136, in if_body_4\n            candidates = ag__.converted_call(ag__.ld(self)._candidates.map, (ag__.ld(enumerate_rows),), None, fscope)\n        File \"C:\\Users\\nurok\\AppData\\Local\\Temp\\__autograph_generated_filesstwdwvb.py\", line 118, in enumerate_rows\n            end_counter = ag__.converted_call(ag__.ld(self)._counter.assign_add, (ag__.converted_call(ag__.ld(tf).shape, (ag__.ld(batch),), None, fscope_3)[0],), None, fscope_3)\n    \n        TypeError: Exception encountered when calling layer 'streaming_2' (type Streaming).\n        \n        in user code:\n        \n            File \"d:\\Work\\movie-recommendation-system\\.venv\\lib\\site-packages\\tensorflow_recommenders\\layers\\factorized_top_k.py\", line 470, in enumerate_rows  *\n                end_counter = self._counter.assign_add(tf.shape(batch)[0])\n        \n            TypeError: Expected any non-tensor type, but got a tensor instead.\n        \n        \n        Call arguments received by layer 'streaming_2' (type Streaming):\n          • queries=tf.Tensor(shape=(None, 32), dtype=float32)\n          • k=100\n    \n    \n    Call arguments received by layer 'retrieval_1' (type Retrieval):\n      • query_embeddings=tf.Tensor(shape=(None, 32), dtype=float32)\n      • candidate_embeddings=tf.Tensor(shape=(None, 32), dtype=float32)\n      • sample_weight=None\n      • candidate_sampling_probability=None\n      • candidate_ids=None\n      • compute_metrics=True\n      • compute_batch_metrics=True\n"
     ]
    }
   ],
   "source": [
    "model = MovieLensModel(user_model, movie_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))\n",
    "\n",
    "cached_train = train.batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()\n",
    "\n",
    "model.fit(cached_train, epochs=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
